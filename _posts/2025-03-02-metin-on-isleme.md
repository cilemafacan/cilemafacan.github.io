---
title: 01-Metin Ã–n Ä°ÅŸleme
layout: post
categories: [Tutorial, NLP Tutorial]
tags: [tutorial]     # TAG names should always be lowercase
author: 01
---

# ğŸ“Œ Metin Ã–n Ä°ÅŸleme: Neden Ã–nemlidir?

DoÄŸal Dil Ä°ÅŸleme (NLP) projelerinde ham metin verisi, Ã§oÄŸu zaman doÄŸrudan analiz veya modelleme iÃ§in kullanÄ±lamaz. Metinler; dÃ¼zensiz karakterler, noktalama iÅŸaretleri, gereksiz kelimeler ve biÃ§imsel farklÄ±lÄ±klar iÃ§erebilir. Bu nedenle, metinlerin doÄŸru ve etkili bir ÅŸekilde iÅŸlenebilmesi iÃ§in Ã¶n iÅŸleme adÄ±mlarÄ± uygulanmalÄ±dÄ±r.

Metin Ã¶n iÅŸleme, veriyi daha temiz, tutarlÄ± ve iÅŸlenebilir hale getirmek iÃ§in yapÄ±lan bir dizi dÃ¶nÃ¼ÅŸÃ¼m sÃ¼recini kapsar. Bu sÃ¼reÃ§, kullanÄ±lan modele ve uygulama alanÄ±na baÄŸlÄ± olarak deÄŸiÅŸebilir ancak genel olarak ÅŸu nedenlerle kritik bir Ã¶neme sahiptir:

âœ… **GÃ¼rÃ¼ltÃ¼yÃ¼ Azaltma**: Gereksiz karakterler, semboller ve durak (stop) kelimelerinin kaldÄ±rÄ±lmasÄ±, veriyi daha anlamlÄ± hale getirir.  
âœ… **Veri TutarlÄ±lÄ±ÄŸÄ±nÄ± ArtÄ±rma**: FarklÄ± biÃ§imlerde yazÄ±lmÄ±ÅŸ kelimeleri normalize etmek, metnin daha tutarlÄ± olmasÄ±nÄ± saÄŸlar.  
âœ… **Hesaplama Maliyetini Azaltma**: Gereksiz veriyi eleyerek modelin daha verimli Ã§alÄ±ÅŸmasÄ±na yardÄ±mcÄ± olur.  
âœ… **GenelleÅŸtirme YeteneÄŸini ArtÄ±rma**: Kelime kÃ¶klerine indirgeme (stemming/lemmatization) gibi iÅŸlemler, modelin farklÄ± baÄŸlamlarda da iyi performans gÃ¶stermesini saÄŸlar.  

---

## ğŸ” Metin Ã–n Ä°ÅŸleme AÅŸamalarÄ±  

Metin Ã¶n iÅŸleme sÃ¼reci, Ã§eÅŸitli dÃ¶nÃ¼ÅŸÃ¼mleri iÃ§eren birden fazla adÄ±mdan oluÅŸur:

1ï¸âƒ£ **BÃ¼yÃ¼k/KÃ¼Ã§Ã¼k Harf DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Lowercasing)**: Metindeki tÃ¼m harflerin kÃ¼Ã§Ã¼k harfe Ã§evrilmesi.  
2ï¸âƒ£ **Noktalama Ä°ÅŸaretlerinin KaldÄ±rÄ±lmasÄ± (Removing Punctuation)**: Noktalama iÅŸaretlerinin silinmesi veya gerektiÄŸinde deÄŸiÅŸtirilmesi.  
3ï¸âƒ£ **SayÄ±larÄ±n KaldÄ±rÄ±lmasÄ± (Removing Numbers)**: SayÄ±larÄ±n metinden Ã§Ä±karÄ±lmasÄ± (bazÄ± durumlarda korunabilir).  
4ï¸âƒ£ **Durak Kelimelerin KaldÄ±rÄ±lmasÄ± (Removing Stopwords)**: "ve", "bu", "bir" gibi bilgi taÅŸÄ±mayan yaygÄ±n kelimelerin Ã§Ä±karÄ±lmasÄ±.  
5ï¸âƒ£ **Ã–zel Karakterlerin ve Emojilerin KaldÄ±rÄ±lmasÄ± (Removing Special Characters & Emojis)**: Metindeki Ã¶zel sembollerin ve emojilerin temizlenmesi.  
6ï¸âƒ£ **Metin Normalizasyonu (Text Normalization)**: Kelimelerin standart bir forma dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi (Ã¶rneÄŸin, "olmÄ±yacak" â†’ "olmayacak", "tlfn" â†’ "telefon").  
7ï¸âƒ£ **KÃ¶k veya GÃ¶vdeye Ä°ndirgeme (Stemming & Lemmatization)**: Kelimeleri kÃ¶k haline getirme (stemming) veya kÃ¶kÃ¼ne en yakÄ±n hÃ¢le getirme (lemmatization).  
8ï¸âƒ£ **Kelime Tokenizasyonu (Tokenization)**: Metni kelime veya cÃ¼mlelere ayÄ±rma.   

```python
import os
import kagglehub
import pandas as pd

path = kagglehub.dataset_download("mustfkeskin/turkish-movie-sentiment-analysis-dataset")
dataset_name = os.listdir(path)[0]
print("Path to dataset files:", path)
print("Dataset name:", dataset_name)
````
```python
df = pd.read_csv(os.path.join(path, dataset_name))
print(df["comment"][4])
df.head()
```
---

## ğŸ“Œ 1. AÅŸama: Lowercasing (KÃ¼Ã§Ã¼k Harfe Ã‡evirme)

**Neden Ã–nemlidir?**  
Metinlerde bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarlÄ±lÄ±ÄŸÄ± nedeniyle aynÄ± kelimeler farklÄ± ÅŸekilde yorumlanabilir.  
Ã–rneÄŸin, "Film" ve "film" kelimeleri aslÄ±nda aynÄ±dÄ±r, ancak bÃ¼yÃ¼k harf farkÄ± nedeniyle farklÄ± olarak algÄ±lanabilir.  
Bunu Ã¶nlemek iÃ§in tÃ¼m metni kÃ¼Ã§Ã¼k harfe Ã§evirmeliyiz.

### ğŸ”¹ Ã–rnek:
- **Girdi:** `"Bu Film HARÄ°KAYDI!"`
- **Ã‡Ä±ktÄ±:** `"bu film harikaydÄ±!"`

AÅŸaÄŸÄ±daki kod bloÄŸu, veri setindeki belirli bir sÃ¼tunu tamamen kÃ¼Ã§Ã¼k harfe Ã§evirerek normalize eder.

```python
text_column = "comment" 

print("GÄ°RDÄ°:", df[text_column][4])

df[text_column] = df[text_column].str.lower()

print("Ã‡IKTI:", df[text_column][4])
```

---

## ğŸ“ 2. AÅŸama: Noktalama Ä°ÅŸaretlerini Temizleme

### **Neden Ã–nemlidir?**
Metinlerdeki noktalama iÅŸaretleri, dilin yapÄ±sal Ã¶ÄŸeleri olup, modelin anlam Ã§Ä±karma ve analiz yapma konusunda yanÄ±ltÄ±cÄ± olabilir. Ã–rneÄŸin, bir cÃ¼mledeki noktalama iÅŸaretleri, genellikle anlam taÅŸÄ±mayan karakterlerdir. Noktalama iÅŸaretlerini temizlemek, metni daha uygun hale getirebilir.

### ğŸ”¹ **Ã–rnek:**
- **Girdi:** `"Film harikaydÄ±, ancak biraz uzun."`
- **Ã‡Ä±ktÄ±:** `"film harikaydi ancak biraz uzun"`

### ğŸ› ï¸ **Noktalama Ä°ÅŸaretlerini Temizleme AdÄ±mlarÄ±:**
Bu aÅŸamada, metinden tÃ¼m noktalama iÅŸaretlerini kaldÄ±racaÄŸÄ±z. Bunun iÃ§in **regex** kullanarak, metin iÃ§indeki noktalama iÅŸaretlerini temizleyeceÄŸiz.

```python
import string

string.punctuation
print("GÄ°RDÄ°:", df[text_column][4])

df[text_column] = df[text_column].str.replace(f"[{string.punctuation}]", "", regex=True)

print("Ã‡IKTI:", df[text_column][4])
``` 

---

## ğŸ“ 3. AÅŸama: SayÄ±larÄ± Temizleme

### **Neden Ã–nemlidir?**
Metinlerde bulunan sayÄ±lar, genellikle model iÃ§in anlam taÅŸÄ±maz. EÄŸer verisetinde belirli bir sayÄ±sal bilgi yoksa ya da sayÄ±lar analizi etkilemeyecekse, bunlarÄ±n metinden Ã§Ä±karÄ±lmasÄ± gerekebilir. Ã–zellikle duygu analizi gibi gÃ¶revlerde sayÄ±lar, anlamlÄ± bir bilgi taÅŸÄ±maz. 

### ğŸ”¹ **Ã–rnek:**
- **Girdi:** `"Bu film 2021 yÄ±lÄ±nda vizyona girdi."`
- **Ã‡Ä±ktÄ±:** `"bu film yÄ±lÄ±nda vizyona girdi"`

### ğŸ› ï¸ **SayÄ±larÄ± Temizleme AdÄ±mlarÄ±:**
Bu aÅŸamada, metindeki sayÄ±larÄ± kaldÄ±racaÄŸÄ±z. Bunun iÃ§in **regex** kullanarak sayÄ±larÄ± temizleyeceÄŸiz.

```python
print("GÄ°RDÄ°:", df[text_column][4])
df[text_column] = df[text_column].str.replace(r'\d+', '', regex=True)

print("Ã‡IKTI:", df[text_column][4])
```

---

## ğŸ“ 4. AÅŸama: Stopwords (AnlamsÄ±z Kelimeleri) Temizleme

### **Neden Ã–nemlidir?**
**Stopwords**, dilin temel yapÄ± taÅŸlarÄ± olan ve genellikle anlam taÅŸÄ±mayan, Ã§ok sÄ±k kullanÄ±lan kelimelerdir. Bu kelimeler, modelin anlamlÄ± bilgi Ã¶ÄŸrenmesini engelleyebilir. Ã–rneÄŸin, "ve", "bir", "ile" gibi kelimeler bir cÃ¼mlenin anlamÄ±nÄ± deÄŸiÅŸtirmez, ancak metin analizinde yer almasÄ± modelin yanlÄ±ÅŸ Ã¶ÄŸrenmesine yol aÃ§abilir. Bu yÃ¼zden stopwords'leri metinden Ã§Ä±kararak metni sadeleÅŸtirebiliriz.

### ğŸ”¹ **Ã–rnek:**
- **Girdi:** `"Film Ã§ok gÃ¼zeldi ve oyunculuk harikaydÄ±."`
- **Ã‡Ä±ktÄ±:** `"film gÃ¼zeldi oyunculuk harikaydÄ±"`

### ğŸ› ï¸ **Stopwords Temizleme AdÄ±mlarÄ±:**
Bu adÄ±mda, TÃ¼rkÃ§e stopwords listesini kullanarak metin iÃ§indeki anlamsÄ±z kelimeleri temizleyeceÄŸiz.

```python
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

stop_words = set(stopwords.words('turkish'))
print("STOPWORDS:", stop_words)

print("GÄ°RDÄ°:", df[text_column][4])
df[text_column] = df[text_column].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))
print("Ã‡IKTI:", df[text_column][4])
```

---

## ğŸ“ 5. AÅŸama: Ã–zel Karakterlerin ve Emojilerin KaldÄ±rÄ±lmasÄ±

### **Neden Ã–nemlidir?**
Metinlerdeki Ã¶zel karakterler ve emojiler, modelin doÄŸru ÅŸekilde Ã¶ÄŸrenmesi iÃ§in genellikle gereksizdir. Ã–zellikle duygu analizi veya metin sÄ±nÄ±flandÄ±rma gibi gÃ¶revlerde, bu semboller anlam taÅŸÄ±maz ve metnin doÄŸasÄ±na zarar verebilir. Bu yÃ¼zden, emojiler ve Ã¶zel karakterler, metin iÅŸleme sÃ¼recinde temizlenmesi gereken Ã¶ÄŸelerdir.

### ğŸ”¹ **Ã–rnek:**
- **Girdi:** `"Film harikaydÄ±! ğŸ˜ğŸ¬ Ã‡ok eÄŸlenceliydi... :)"`
- **Ã‡Ä±ktÄ±:** `"film harikaydi cok eglenceliydi"`

### ğŸ› ï¸ **Ã–zel Karakterlerin ve Emojilerin KaldÄ±rÄ±lmasÄ± AdÄ±mlarÄ±:**
Bu adÄ±mda, metindeki tÃ¼m Ã¶zel karakterleri ve emojileri kaldÄ±racaÄŸÄ±z. Bunun iÃ§in regex kullanarak bu karakterleri temizleyeceÄŸiz.

```python
import re

def convert_turkish_chars(text):
    turkish_chars = {
        'Ã§': 'c', 'Ä±': 'i', 'ÄŸ': 'g', 'ÅŸ': 's', 'Ã¼': 'u', 'Ã¶': 'o', 'Ã‡': 'C', 'Ä°': 'I', 'Ä': 'G', 'Å': 'S', 'Ãœ': 'U', 'Ã–': 'O'
    }
    for turkish_char, english_char in turkish_chars.items():
        text = text.replace(turkish_char, english_char)
    return text


def remove_special_characters_and_emojis(text):
    text = convert_turkish_chars(text)
    text = re.sub(r'[^\w\s]', '', text) 
    text = re.sub(r'[^\x00-\x7F]+', '', text)  
    return text


print("GÄ°RDÄ°:", df[text_column][588])
df[text_column] = df[text_column].apply(remove_special_characters_and_emojis)
print("Ã‡IKTI:", df[text_column][588])
```

---

## ğŸ“ 6. AÅŸama: Metin Normalizasyonu (Text Normalization)

### **Neden Ã–nemlidir?**
Metin normalizasyonu, metinlerdeki varyasyonlarÄ± ortadan kaldÄ±rarak daha tutarlÄ± ve temiz veriler elde etmemizi saÄŸlar. Bu iÅŸlem, yazÄ±m hatalarÄ±, kÄ±saltmalar ve dildeki diÄŸer tutarsÄ±zlÄ±klarÄ±n dÃ¼zeltilmesine yardÄ±mcÄ± olur. Modelin daha etkili bir ÅŸekilde Ã¶ÄŸrenmesi iÃ§in metnin daha anlaÅŸÄ±lÄ±r ve dÃ¼zenli hale getirilmesi gereklidir.

### ğŸ”¹ **Ã–rnek:**
- **Girdi:** `"YazÄ±lÄ±m olmyacak, ama tlfn alcam!"`
- **Ã‡Ä±ktÄ±:** `"yazilim olmayacak ama telefon alacagim"`

### ğŸ› ï¸ **Metin Normalizasyonu AdÄ±mlarÄ±:**
Bu adÄ±mda, yazÄ±m hatalarÄ±nÄ± dÃ¼zeltecek ve bazÄ± yaygÄ±n kÄ±saltmalarÄ± geniÅŸleterek daha standart bir forma dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz. Bunun iÃ§in bir kelime eÅŸlemesi (dictionary) kullanabiliriz.

```python

normalization_dict = {
    'tmm': 'tamam',
    'gzl': 'guzel'
}

def normalize_text(text):
    text = text.lower() 
    for word, normalized_word in normalization_dict.items():
        text = re.sub(r'\b' + word + r'\b', normalized_word, text)
    return text

print("GÄ°RDÄ°:", df[text_column][2232])

df['comment'] = df['comment'].apply(normalize_text)

print("Ã‡IKTI:", df[text_column][2232])
```

---

### ğŸ“ **7. AÅŸama: KÃ¶k veya GÃ¶vdeye Ä°ndirgeme (Stemming & Lemmatization)**

**Neden Ã–nemlidir?**  
Metindeki kelimeleri kÃ¶klerine indirgeme (stemming) veya kÃ¶klerine en yakÄ±n hale getirme (lemmatization), kelimelerin farklÄ± biÃ§imlerini tek bir temsil ile ifade eder. Bu, modelin daha anlamlÄ± bir ÅŸekilde Ã§alÄ±ÅŸmasÄ±na yardÄ±mcÄ± olur. Ã–rneÄŸin, "yazÄ±yorum", "yazdÄ±" ve "yazmak" kelimeleri kÃ¶klerine indirgenerek hepsi "yaz" olarak iÅŸlenebilir. Bu, dilin Ã§eÅŸitli tÃ¼revlerinin anlamÄ±nÄ± birleÅŸtirir ve modelin Ã¶ÄŸrenmesini iyileÅŸtirir.

---

**Stemming ve Lemmatization ArasÄ±ndaki Farklar:**

- **Stemming**: Kelimenin kÃ¶kÃ¼ne indirgeme iÅŸlemi yapar, ancak bazÄ± kelimeleri yanlÄ±ÅŸ kÃ¶klerle eÅŸleÅŸtirebilir. Ã–rneÄŸin, "yazmak" kelimesi "yaz" olarak indirgenir.
  
- **Lemmatization**: Daha geliÅŸmiÅŸ bir iÅŸlemdir. Kelimenin doÄŸru kÃ¶k biÃ§imini bulur. "yazmak" â†’ "yaz", "gÃ¼zel" â†’ "gÃ¼zel" gibi. Bu iÅŸlem iÃ§in bir kelime Ã§Ã¶zÃ¼mleyici (lemmatizer) kullanÄ±lÄ±r.

### 1ï¸âƒ£ **Stemming Ã–rneÄŸi:**

```python

from jpype import startJVM, JClass, shutdownJVM
ZEMBEREK_PATH = "./zemberek-full.jar" 

startJVM(classpath=ZEMBEREK_PATH)

TurkishMorphology = JClass("zemberek.morphology.TurkishMorphology")
morphology = TurkishMorphology.createWithDefaults()

def stem(word):
    analysis = morphology.analyze(word)
    results = [str(result.getStem()) for result in analysis]
    return results[0] if results else word

print("GÄ°RDÄ°:", df[text_column][10])
word_list = df[text_column][10].split()
print("Ã‡IKTI:", [stem(word) for word in word_list])

shutdownJVM()
```

### 2ï¸âƒ£ **Lemmatization Ã–rneÄŸi:**

```python
from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()

def lemmatization(text):
    words = text.split()
    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
    return ' '.join(lemmatized_words)


print("GÄ°RDÄ°:", df[text_column][2])

print("Ã‡IKTI:", lemmatization(df[text_column][2]))
```

## ğŸ“ 8. AÅŸama: Kelime Tokenizasyonu (Tokenization)

### ğŸš€ Neden Ã–nemlidir?
Kelime tokenizasyonu, metni daha kÃ¼Ã§Ã¼k birimlere (kelime veya cÃ¼mlelere) ayÄ±rma iÅŸlemdir. DoÄŸal dil iÅŸleme (NLP) sÃ¼reÃ§lerinde veriyi daha anlamlÄ± hale getirmek iÃ§in temel bir adÄ±mdÄ±r.

**Ã–rneÄŸin:**

- **Kelime BazlÄ± Tokenizasyon:**  
  *"BugÃ¼n hava Ã§ok gÃ¼zel!"*  
  Tokenizasyon iÅŸlemi: `["BugÃ¼n", "hava", "Ã§ok", "gÃ¼zel", "!"]`

- **CÃ¼mle BazlÄ± Tokenizasyon:**  
  *"BugÃ¼n hava Ã§ok gÃ¼zel! DÄ±ÅŸarÄ± Ã§Ä±kalÄ±m mÄ±?"*  
  Tokenizasyon iÅŸlemi: `["BugÃ¼n hava Ã§ok gÃ¼zel!", "DÄ±ÅŸarÄ± Ã§Ä±kalÄ±m mÄ±?"]`

### ğŸ›  Tokenizasyon TÃ¼rleri
1. **Kelime BazlÄ± Tokenizasyon:** CÃ¼mleyi kelimelere bÃ¶ler.
2. **CÃ¼mle BazlÄ± Tokenizasyon:** Metni cÃ¼mlelere bÃ¶ler.
3. **Alt Kelime (Subword) Tokenizasyonu:** Ã–zel karakterleri ve ekleri de hesaba katarak parÃ§alama yapar.

```python
from trtokenizer.tr_tokenizer import SentenceTokenizer, WordTokenizer


sentence_tokenizer = SentenceTokenizer()

print("GÄ°RDÄ°:", df[text_column][0])

print("Ã‡IKTI:", sentence_tokenizer.tokenize(df[text_column][0]))

word_tokenizer = WordTokenizer()

print("Ã‡IKTI:", word_tokenizer.tokenize(df[text_column][0]))
```

